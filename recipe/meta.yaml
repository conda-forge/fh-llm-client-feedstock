{% set name = "fh-llm-client" %}
{% set version = "0.1.0" %}
{% set python_min = "3.11" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/fh_llm_client-{{ version }}.tar.gz
  sha256: 859da187b0e5b24545828fd88f9a16be9ca4f46a2443f6ba3665759609823725

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - setuptools >=64
    - setuptools-scm >=8
    - pip
  run:
    - typing_extensions
    - python >={{ python_min }}
    - coredis
    - fhaviary >=0.14.0
    - limits
    - pydantic >=2.0,<3.dev0,>=2.10.1,<2.10.2
    - tiktoken >=0.4.0
    - litellm >=1.60.2

test:
  imports:
    - llmclient
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  summary: A client to provide LLM responses for FutureHouse applications.
  home: https://github.com/Future-House/llm-client
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
